{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pyplot.pyplot",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-65c2caf355cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# notes and figures from various sources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pyplot.pyplot"
     ]
    }
   ],
   "source": [
    "# notes and figures from various sources\n",
    "import pyplot.pyplot as py\n",
    "import numpy as np\n",
    "import json, yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a temperature and alpha parameter, fix words in lexicon, prior probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "RSA Fundamentals:\n",
    "\n",
    "Elements: literal listener $L_0$, pragmatic speaker $S_1$, pragmatic listener $L_2$, cost function on dialogue (fixed utterances?) $\\kappa$, inverse temperature parameter $\\alpha$, prior probabilities of referents $P$, prior probabilities (truth functions?) of utterances referring to referents $L$, current referent $r$, current utterance $u$.\n",
    "\n",
    "---\n",
    "\n",
    "Literal Listener:\n",
    "\n",
    "$l_o(r\\,|\\,u, L)\\,\\propto\\,L(u\\,|\\,r)\\,P(r)$\n",
    "\n",
    "\n",
    "\n",
    "Pragmatic Speaker:\n",
    "\n",
    "\n",
    "$s_1(u\\,|\\,r, L)\\,\\propto\\,e\\,^{\\alpha\\log{l_o(r\\,|\\,u, L)}\\,-\\,\\kappa(u)}$\n",
    "\n",
    "\n",
    "Pragmatic Listener:\n",
    "\n",
    "$l_2(r\\,|\\,u, L)\\,\\propto\\,s_1(u\\,|\\,t,\\,L)\\,P(r)$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "This back and forth nature addresses Grice's conversational implicature theory but poses an obvious paradoxical problem i.e., it is always optimal to soft-maximise the current previous agent i.e., use strategy $S_{n-1}$ at whatever iteration you are at and use Bayes ruleto invert their decision procedure. I think most of the work in this setting so far sets recursion depth = 3. \n",
    "\n",
    "Final equilibirium state currently is when only one agent is optimal wrt. the game, the other is $nearly$ optimal i.e., off by one iteration.\n",
    "\n",
    "---\n",
    "\n",
    "(read Goodman NIPS 13, Potts NAACL 18)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''def get_s1(l0, alpha):\n",
    "    l0_a = l0 * alpha; s1 = l0_a - logsumexp(l0_a, axis=2)\n",
    "    return s1\n",
    "\n",
    "def get_l2(s1):\n",
    "    l2 = s1 - logsumexp(s1, axis=3)\n",
    "    return l2\n",
    "\n",
    "def get_lstar(l0, l2, bw):\n",
    "    unnorm = (bw * l0 + (1 - bw) * l2)[:, :, 0, :]; lstar = unnorm - logsumexp(unnorm, axis=2)\n",
    "    return lstar'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Old RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shared lexicon, experiment with concatenated i.e., shared, individual. incorporate perturbations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumptions made:\n",
    "\n",
    "1. All agents have knowledge of a shared lexicon that they update priors over.\n",
    "2. They have full knowledge of the cost function.\n",
    "3. Main assumption is that there exists a single, shared lexicon that everyone should be using and I, as an agent, know that the other agent knows it and this is what I want to learn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#incorporate shared, individual. incorporate perturbations (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "LSTM encoders output Gaussian distributions over referents, then softmax and classify for most probable referent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import os, sys, re, random\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "def row_norm(m):\n",
    "    return np.divide(m.T, np.sum(m, axis=1)).T\n",
    "\n",
    "def col_norm(m):\n",
    "    return np.divide(m, np.sum(m, axis=0))\n",
    "\n",
    "def safe_log(x):\n",
    "    with np.errstate(divide='ignore'):\n",
    "        return np.log(x)\n",
    "    \n",
    "def inner_product(x, y):\n",
    "    return np.dot(x, y)\n",
    "\n",
    "def powerset(x, minsize=0, maxsize=None):\n",
    "    result = []\n",
    "    if maxsize == None: maxsize = len(x)\n",
    "    for i in range(minsize, maxsize+1):\n",
    "        for val in combinations(x, i): result.append(list(val))\n",
    "    return result\n",
    "\n",
    "def mean_sq_error(x, y):\n",
    "    return np.mean((x-y)**2)\n",
    "\n",
    "def display_matrix(m, rnames=None, cnames=None, title='', digits=4):\n",
    "    rwidth = 2 + max([len(x) for x in rnames] + [digits+2])\n",
    "    cwidth = 2 + max([len(x) for x in cnames] + [digits+2])\n",
    "    m = np.round(m, digits)\n",
    "    s = ''; divider = ''; linebreak = '\\n';\n",
    "    for i in range(m.shape[0]):\n",
    "        rowcontents = divider.join(str(x).rjust(cwidth) for x in m[i, :])\n",
    "        s += str(rnames[i]).rjust(rwidth) + divider + rowcontents + linebreak\n",
    "    print s\n",
    "    \n",
    "m = np.matrix([[1.0, 2.0], [3.0, 4.0]])\n",
    "m = row_norm(m); print m\n",
    "m = col_norm(m); print m\n",
    "\n",
    "#### Define encapsulating class\n",
    "\n",
    "class Module:\n",
    "    def __init__(self,\n",
    "                lexica=None,\n",
    "                baselexicon=None,\n",
    "                states=None,\n",
    "                costs=None,\n",
    "                messages=None,\n",
    "                prior=None,\n",
    "                lexprior=None,\n",
    "                lexcount=None, \n",
    "                temperature=1.0,\n",
    "                alpha=1.0,\n",
    "                beta=1.0,\n",
    "                nullmsg=True,\n",
    "                nullcost=5.0):\n",
    "        self.lexica = lexica\n",
    "        self.baselexicon = baselexicon\n",
    "        self.states = states\n",
    "        self.costs = costs\n",
    "        self.messages = messages\n",
    "        self.prior = prior\n",
    "        self.lexprior = lexprior\n",
    "        self.lexcount = lexcount\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta \n",
    "        self.nullmsg = nullmsg\n",
    "        self.nullcost = nullcost\n",
    "        \n",
    "        #intialise base prior arrays \n",
    "        if type(self.prior) == type(None):\n",
    "            val = 1.0/len(self.states)\n",
    "            self.prior = np.repeat(val, len(self.states))\n",
    "        if type(self.lexprior) == type(None) and self.lexcount != None:\n",
    "            val = 1.0/len(self.lexcount)\n",
    "            self.prior = np.repeat(val, len(self.lexcount))\n",
    "        else:\n",
    "            self.lexprior = defaultdict(lambda: 1.0)\n",
    "        if type(self.costs) == type(None):\n",
    "            self.costs = np.zeros(len(self.messages))\n",
    "            if self.nullmsg:\n",
    "                self.costs[-1] = self.nullcost\n",
    "        self.final_listener = np.zeros((len(self.messages), len(self.states)))\n",
    "        self.final_speaker = None  \n",
    "\n",
    "\n",
    "####  Interaction iterative functions\n",
    "\n",
    "    def rsa(self, lex=None):\n",
    "        if lex is None: lex = self.baselexicon\n",
    "        literal = self.l0(lex)\n",
    "        speaker = self.S(literal)\n",
    "        listener = self.L(speaker)\n",
    "        return [literal, speaker, listener]\n",
    "\n",
    "    def run_base_model(self, lex, n=2, display=True, digits=4):\n",
    "        return self.run(\n",
    "                    n=n, \n",
    "                    display=display, \n",
    "                    digits=digits,\n",
    "                    initial_listener = self.l0(lex),\n",
    "                    start_level=0)\n",
    "\n",
    "    def run(self,\n",
    "       initial_listener,\n",
    "       n=2,\n",
    "       display=True,\n",
    "       digits=4,\n",
    "       start_level=0,\n",
    "       ):\n",
    "    #langs\n",
    "        langs = [initial_listener]\n",
    "        for i in range(1, (n-1)*2, 2):\n",
    "            langs.append(self.S(langs[i-1]))\n",
    "            langs.append(self.L(langs[i]))\n",
    "        \n",
    "        if len(langs) < 2:\n",
    "            self.final_speaker = None\n",
    "            self.final_listener = langs[-1]\n",
    "        else:\n",
    "            self.final_speaker, self.final_listener = langs[-2:]\n",
    "        \n",
    "        if display:\n",
    "            self.display_iteration(langs, start_level=start_level, digits=digits)\n",
    "        return langs\n",
    "    \n",
    "\n",
    "#### Agents\n",
    "\n",
    "    def l0(self, lex):\n",
    "        return row_norm(lex*self.prior)\n",
    "\n",
    "    def L(self, speaker):\n",
    "        return self.l0(speaker.T)\n",
    "\n",
    "    def S(self, listener):\n",
    "        return row_norm(np.exp(self.temperature * ((self.alpha*safe_log(listener.T)) - self.costs)))\n",
    "\n",
    "    def s1(self, lex):\n",
    "        return self.S(self.l0(lex))\n",
    "\n",
    "    def l1(self, lex):\n",
    "        return self.L(self.s1(lex))\n",
    "\n",
    "    def lex_likelihood(self):\n",
    "        p = np.array([np.sum(self.s1(lex), axis=0) * self.lexprior[i] for i, lex in enumerate(self.lexica)])\n",
    "        return col_norm(p)\n",
    "\n",
    "    def listener_lexical_marginalisation(self, listener):\n",
    "        return np.sum(listener, axis=1)\n",
    "\n",
    "    def speaker_lexical_marginalisation(self, speaker):\n",
    "        return row_norm(np.sum(speaker, axis=0))\n",
    "\n",
    "#### $\\rightarrow$ Display functions\n",
    "\n",
    "    def display_expertise_iteration(self, langs, digits=4):\n",
    "        \"\"\"Display the full iteration for any the expertise model\"\"\"       \n",
    "        level = 1\n",
    "        for index in range(0, len(langs)-1, 2):\n",
    "            self.display_joint_listener_matrices(\n",
    "                langs[index], level=level, digits=digits)\n",
    "            self.display_listener_matrix(\n",
    "                self.listener_lexical_marginalization(langs[index]),\n",
    "                title=\"{} - marginalized\".format(level),\n",
    "                digits=digits)                        \n",
    "            level += 1\n",
    "            self.display_expert_speaker_matrices(\n",
    "                langs[index+1], level=level, digits=digits)\n",
    "            self.display_speaker_matrix(\n",
    "                self.speaker_lexical_marginalization(langs[index+1]),\n",
    "                title='{} - marginalized'.format(level),\n",
    "                digits=digits)\n",
    "            \n",
    "    def display_iteration(self, langs, start_level=0, digits=4):\n",
    "        \"\"\"Display the full iteration for any model except expertise\"\"\"\n",
    "        self.display_listener_matrix(\n",
    "            langs[0], title=start_level, digits=digits)        \n",
    "        start_level += 1\n",
    "        display_funcs = (self.display_speaker_matrix,\n",
    "                         self.display_listener_matrix)\n",
    "        for i, lang in enumerate(langs[1: ]):\n",
    "            display_funcs[i % 2](lang, title=start_level, digits=digits)\n",
    "            if i % 2: start_level += 1\n",
    "\n",
    "    def display_speaker_matrix(self, mat, title='', digits=4):\n",
    "        \"\"\"Pretty-printed (to stdout) speaker matrix to standard output\"\"\"\n",
    "        display_matrix(\n",
    "            mat,\n",
    "            title='S{}'.format(title),\n",
    "            rnames=self.states,\n",
    "            cnames=self.messages,\n",
    "            digits=digits)\n",
    "\n",
    "    def display_listener_matrix(self, mat, title='', digits=4):\n",
    "        \"\"\"Pretty-printed (to stdout) listener matrix to standard output\"\"\"\n",
    "        display_matrix(\n",
    "            mat,\n",
    "            title='L{}'.format(title),\n",
    "            rnames=self.messages,\n",
    "            cnames=self.states,\n",
    "            digits=digits)\n",
    "\n",
    "    def display_joint_listener(self, mat, title='', digits=4):\n",
    "        \"\"\"Pretty-printed (to stdout) lexicon x world joint probability\n",
    "        table for a given message\"\"\"\n",
    "        lexnames = ['Lex%s: %s' % (i, self.lex2str(lex))\n",
    "                    for i, lex in enumerate(self.lexica)]\n",
    "        display_matrix(\n",
    "            mat,\n",
    "            rnames=lexnames,\n",
    "            cnames=self.states,\n",
    "            title=title,\n",
    "            digits=digits)        \n",
    "\n",
    "    def display_joint_listener_matrices(self, mats, level=1, digits=4):\n",
    "        \"\"\"Pretty-printed (to stdout) lexicon x world joint probability\n",
    "        table for all messages\"\"\"\n",
    "        [self.display_joint_listener(\n",
    "            mat,\n",
    "            title='L{} - {}'.format(level, self.messages[i]),\n",
    "            digits=digits)\n",
    "         for i, mat in enumerate(mats)]\n",
    "        \n",
    "    def display_expert_speaker_matrices(self, mats, level=1, digits=4):\n",
    "        \"\"\"Pretty-printed (to stdout) list of world x message\n",
    "        conditional probability tables, one for each lexicon\"\"\"\n",
    "        [self.display_speaker_matrix(\n",
    "            mat,\n",
    "            title='{} - Lex{} {}'.format(level, i, self.lex2str(self.lexica[i])),\n",
    "            digits=digits)\n",
    "        for i, mat in enumerate(mats)]\n",
    "\n",
    "\n",
    "\n",
    "    def get_best_inferences(self, digits=4):    \n",
    "        best_inferences = {}\n",
    "        # Round to avoid tiny distinctions that don't even display:\n",
    "        mat = np.round(copy(self.final_listener), 10)\n",
    "        for i, msg in enumerate(self.messages):\n",
    "            best_inferences[msg] = [(w, str(np.round(mat[i,j], digits)))\n",
    "                                    for j, w in enumerate(self.states)\n",
    "                                    if mat[i,j] == np.max(mat[i])]             \n",
    "        return best_inferences   \n",
    "\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test!\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print 'Inside main!'\n",
    "    \n",
    "    #propositions and null message\n",
    "    TT = [1.0, 1.0]; TF = [1.0, 0.0]; FT = [0.0, 1.0]\n",
    "    nullsem = [1.0, 0.0]\n",
    "    \n",
    "    #logically distinct lexica\n",
    "    lexica = [\n",
    "        np.array([TT, TT, nullsem]),\n",
    "        np.array([TT, TF, nullsem]),\n",
    "        np.array([TT, FT, nullsem]),\n",
    "        np.array([TF, TT, nullsem]),\n",
    "        np.array([TF, TF, nullsem]),\n",
    "        np.array([TF, FT, nullsem]),\n",
    "        np.array([FT, TT, nullsem]),\n",
    "        np.array([FT, TF, nullsem]),\n",
    "        np.array([FT, FT, nullsem])]\n",
    "    \n",
    "    mod = Module(\n",
    "    lexica = lexica,\n",
    "    messages=['word_1', 'word_2', 'null'],\n",
    "    costs=np.array([1.0, 2.0, 5.0]),\n",
    "    states = ['ref_1', 'ref_2'],\n",
    "    prior=np.array([2.0/3.0, 1.0/3.0]),\n",
    "    lexprior=np.repeat(1.0/len(lexica), len(lexica)),\n",
    "    temperature=3.0,\n",
    "    alpha=1.0,\n",
    "    beta=1.0)\n",
    "    \n",
    "    n = 2; \n",
    "    \n",
    "    print 'n = ' + str(n) + '\\n'\n",
    "    print 'Creating models!\\n'\n",
    "    baselangs = mod.run_base_model(lexica[6], n=n, display=False)\n",
    "    \n",
    "    print 'Essentially RSA does:\\nliteral = self.l0(lex)\\nspeaker = self.S(literal)\\nlistener = self.L(speaker)\\n'\n",
    "    print 'Final listener!\\n'\n",
    "    mod.display_listener_matrix(\n",
    "        baselangs[-1],\n",
    "        title=\" - Base model\")\n",
    "    print 'Final speaker!\\n'\n",
    "    mod.display_speaker_matrix(\n",
    "        baselangs[-2],\n",
    "        title=\" - Base model\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
