{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "thoughts: what is the fundamental question with respect to categorisation? is learning a representation the most important part? but once we have a learned representation we can still endlessly argue about how humans really categorise concepts; are we conjuring in our heads a single prototypical representation based on past experience or are we referring to every existing exemplar we have previously encountered? or is there a statistical model that encapsulates both by forming decision boundaries -- and is this what we should use to model all (?) categories in existence. \n",
    "\n",
    "---\n",
    "\n",
    "similarity metrics: what kind of similarity metric in the same space allows you to best determine how similar two vector representations (of categories) are?\n",
    "how does this change if your representations don't share the same space (this part is mostly testing metrics, but important)?\n",
    "\n",
    "---\n",
    "\n",
    "what objectives do we want to train on that best allows us to represent a category the way humans do? \n",
    "\n",
    "---\n",
    "\n",
    "once we have a representation of a concept and what we want to categorise, what is the best way to further generalize to other concepts? how do humans do this? are we conjuring in our minds a prototypical representation of the category based on previous encounters with instances from this category? \n",
    "\n",
    "---\n",
    "\n",
    "can humans learn from sketches and more abstract representations better than photos? children can replicate concepts through sketches -- does training on photos and testing on sketches / allowing generalization through sketches make more sense wrt human learning?\n",
    "\n",
    "---\n",
    "\n",
    "given that sketches are more abstract than colored, pixelated photo images -- does a sketch representation of a category align with deeper layers of a neural network trained on images? and if this is true, is this what is helping them generalise?\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "path = os.getcwd(); cat_path = '/'.join(i for i in path.split('/')[:-1]) + '/proto/data/sketchy/ecategories/'\n",
    "# path to random experimental 10 images for each category\n",
    "categories = os.listdir(cat_path)\n",
    "\n",
    "# shows the different categories in the Sketchy dataset (categories vary for different datasets)\n",
    "def print_category_names():\n",
    "    print 'Length: ' + str(len(categories))\n",
    "    print sorted(set(categories))\n",
    "\n",
    "    \n",
    "# show 'num' 'img_type' images for a category 'category' \n",
    "# e.g., show_category_images('cat', 'sketch', 5) or show_category_images('cat', 'photo', 10)\n",
    "def show_category_images(category, img_type, num):\n",
    "    assert num < 11\n",
    "    assert os.path.isdir(cat_path + category)\n",
    "    f = open(cat_path + category + '/' + img_type + '/filenames.txt')\n",
    "    fnames = [line.strip() for line in f.readlines()[1:]]\n",
    "    for fname in fnames[:num]:\n",
    "        fpath = path + '/data/sketchy/efigs/' + fname\n",
    "        if os.path.isfile(fpath) is False: continue\n",
    "        img = Image.open(fpath)\n",
    "        img = np.array(img).astype(np.uint8)\n",
    "        print np.sum(img)\n",
    "        print 'category: ' + str(category)\n",
    "        plt.imshow(img); plt.show()\n",
    "      \n",
    "    \n",
    "# helper function\n",
    "def get_category_average(category, img_type, num):\n",
    "    assert num < 11\n",
    "    assert os.path.isdir(cat_path + category)\n",
    "    f = open(cat_path + category + '/' + img_type + '/filenames.txt')\n",
    "    fnames = [line.strip() for line in f.readlines()[1:]]\n",
    "    avg = np.zeros((256, 256, 3))\n",
    "    for fname in fnames[:num]:\n",
    "        fpath = path + '/data/sketchy/efigs/' + fname\n",
    "        if os.path.isfile(fpath) is False: continue\n",
    "        img = Image.open(fpath)\n",
    "        avg += np.array(img).astype(np.uint8)\n",
    "    avg = np.array(avg / (1.0*num)).astype(np.uint8)\n",
    "    return avg\n",
    "\n",
    "# show average averaged over 'num' images for category 'category' \n",
    "# e.g., show_category_average('dog', 'sketch', '4')\n",
    "def show_category_average(category, img_type, num):\n",
    "    avg = get_category_average(category, img_type, num)\n",
    "    print 'just your average ' + str(category)\n",
    "    plt.imshow(avg); plt.show()\n",
    "    \n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cos_sim\n",
    "from scipy.stats import spearmanr, entropy\n",
    "from sklearn.metrics import log_loss, mutual_info_score\n",
    "from skimage import data, io, filters, color\n",
    "from PIL import ImageOps\n",
    "from sklearn.decomposition import PCA\n",
    "max_intensity = 255.0\n",
    "\n",
    "def similarity_metrics(img_1, img_2):\n",
    "    #plt.imshow(img_1); plt.show()\n",
    "    #plt.imshow(img_2); plt.show()\n",
    "    \n",
    "    #img_1 = img_1.resize((16, 16)); img_2 = img_2.resize((16, 16))\n",
    "    #img_1, img_2 = ImageOps.invert(img_1), ImageOps.invert(img_2)\n",
    "    img_1 = np.array(img_1).astype(np.uint8)\n",
    "    img_2 = np.array(img_2).astype(np.uint8)\n",
    "    # grayscale\n",
    "    img_1 = color.rgb2gray(img_1)\n",
    "    img_2 = color.rgb2gray(img_2)\n",
    "    # reduce dimensions\n",
    "    n_components = 3\n",
    "    pca = PCA(n_components=n_components); \n",
    "    m1 = pca.fit_transform(img_1); m2 = pca.fit_transform(img_2)\n",
    "    # flatten\n",
    "    m1, m2 = [item for sublist in m1 for item in sublist], [item for sublist in m2 for item in sublist]\n",
    "    # make intensities between 0-1\n",
    "    m1, m2 = m1 / np.sum([max_intensity]), m2 /  np.sum([max_intensity])\n",
    "    # normalise\n",
    "    #m1, m2 = m1 / np.sum(m1), m2 / np.sum(m2)\n",
    "\n",
    "    #plt.imshow(img_2, cmap='gray'); plt.show()\n",
    "    metric_names = ['cos_sim', 'spearmanr', 'abs_diff', 'sq_diff', 'kl', 'mutual_inf']; \n",
    "    metrics = {'cos_sim': cos_sim(np.asarray([m1]), np.asarray([m2]))[0][0],\n",
    "               'spearmanr': spearmanr(m1, m2)[0],\n",
    "               'abs_diff': np.sum((m1.astype(\"float\") - m2.astype(\"float\"))),\n",
    "               'sq_diff:': np.sum((m1.astype(\"float\") - m2.astype(\"float\")) ** 2) / float(m1.shape[0] * m2.shape[0])\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def get_similarity_1(category_1, category_2, img_type):\n",
    "    avg_1 = get_category_average(category_1, img_type, 5)\n",
    "    avg_2 = get_category_average(category_2, img_type, 5)\n",
    "    img_1, img_2 = Image.fromarray(avg_1), Image.fromarray(avg_2)\n",
    "    metrics = similarity_metrics(img_1, img_2)\n",
    "    print metrics\n",
    "\n",
    "def get_similarity_2(category_1, img_type_1, category_2, img_type_2):\n",
    "    avg_1 = get_category_average(category_1, img_type_1, 5)\n",
    "    avg_2 = get_category_average(category_2, img_type_2, 5)\n",
    "    img_1, img_2 = Image.fromarray(avg_1), Image.fromarray(avg_2)\n",
    "    metrics = similarity_metrics(img_1, img_2)\n",
    "    print metrics\n",
    "\n",
    "def get_image(category, img_type):\n",
    "    assert os.path.isdir(cat_path + category)\n",
    "    f = open(cat_path + category + '/' + img_type + '/filenames.txt')\n",
    "    fnames = [line.strip() for line in f.readlines()[1:]]\n",
    "    np.random.shuffle(fnames); fpath = path + '/data/sketchy/efigs/' + fnames[0]\n",
    "    img = Image.open(fpath)\n",
    "    return img\n",
    "\n",
    "def get_similarity_3(category, img_type):\n",
    "    avg = get_category_average(category, img_type, 5)\n",
    "    avg = Image.fromarray(avg)\n",
    "    img = get_image(category, img_type)\n",
    "    metrics = similarity_metrics(img, avg)\n",
    "    print metrics\n",
    "  \n",
    "##\n",
    "import pandas\n",
    "import seaborn as sns\n",
    "# takes in a list of categories and generates a map of similarities\n",
    "# categories = ['cat', 'dog', 'mouse', 'rabbit', 'table', 'couch', 'duck', 'swan', 'penguin', 'dolphin']\n",
    "# e.g., similarity_map(categories, 'sketch', 'cos_sim')\n",
    "def similarity_map(categories, img_type, metric):\n",
    "    sim = np.zeros((len(categories), len(categories)))\n",
    "    for i in range(len(categories)):\n",
    "        for j in range(len(categories)):\n",
    "            avg_1 = get_category_average(categories[i], img_type, 5)\n",
    "            avg_2 = get_category_average(categories[j], img_type, 5)\n",
    "            metrics = similarity_metrics(Image.fromarray(avg_1), Image.fromarray(avg_2))\n",
    "            if metric not in metrics.keys(): continue\n",
    "            sim[i][j] = metrics[metric]\n",
    "            \n",
    "    sns.set()\n",
    "    df = pandas.DataFrame(sim)\n",
    "    df.columns = categories; df.index = categories\n",
    "    ax = sns.heatmap(df, cmap=\"YlGnBu\", annot=True)\n",
    "    ax.set_ylabel(img_type + '_' + metric)\n",
    "    plt.show()\n",
    "    \n",
    "def test():\n",
    "    img_1 = Image.open(path + '/data/sketchy/efigs/n02041246_1477-3.png'); \n",
    "    img_2 = Image.open(path + '/data/sketchy/efigs/n02041246_1477-5.png'); \n",
    "    img_3 = Image.open(path + '/data/sketchy/efigs/n02432983_20607.jpg'); \n",
    "    img_4 = Image.open(path + '/data/sketchy/efigs/n02431337_16475.jpg'); \n",
    "\n",
    "    metrics = similarity_metrics(img_1, img_2)\n",
    "    print metrics\n",
    "    metrics = similarity_metrics(img_1, img_3)\n",
    "    print metrics\n",
    "    metrics = similarity_metrics(img_4, img_3)\n",
    "    print metrics\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_category_images('airplane', 'photo', 2)\n",
    "show_category_average('airplane', 'photo', 5)\n",
    "show_category_images('bicycle', 'sketch', 2)\n",
    "show_category_average('bicycle', 'sketch', 5)\n",
    "\n",
    "show_category_images('wine_bottle', 'photo', 2)\n",
    "show_category_average('wine_bottle', 'sketch', 5)\n",
    "show_category_average('dog', 'sketch', 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaway from results:\n",
    "\n",
    "given (1) doesn't work, we can't learn from the more abstract, but can use it to generalise? \n",
    "\n",
    "does evaluating at every layer give us more insight into this? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read Tom Griffiths \"human-eval\", Beth Levin, Trevor Darrell (?) and other vision folks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
