{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "stray thoughts: is goal-oriented word meaning what we need to be working towards? can RSA fully model this? can communicative contexts and past interactions be used to model word meaning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import os, sys, re, random\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "def row_norm(m):\n",
    "    return np.divide(m.T, np.sum(m, axis=1)).T\n",
    "\n",
    "def col_norm(m):\n",
    "    return np.divide(m, np.sum(m, axis=0))\n",
    "\n",
    "def safe_log(x):\n",
    "    with np.errstate(divide='ignore'):\n",
    "        return np.log(x)\n",
    "    \n",
    "def inner_product(x, y):\n",
    "    return np.dot(x, y)\n",
    "\n",
    "def powerset(x, minsize=0, maxsize=None):\n",
    "    result = []\n",
    "    if maxsize == None: maxsize = len(x)\n",
    "    for i in range(minsize, maxsize+1):\n",
    "        for val in combinations(x, i): result.append(list(val))\n",
    "    return result\n",
    "\n",
    "def mean_sq_error(x, y):\n",
    "    return np.mean((x-y)**2)\n",
    "\n",
    "def display_matrix(m, rnames=None, cnames=None, title='', digits=4):\n",
    "    rwidth = 2 + max([len(x) for x in rnames] + [digits+2])\n",
    "    cwidth = 2 + max([len(x) for x in cnames] + [digits+2])\n",
    "    m = np.round(m, digits)\n",
    "    s = ''; divider = ''; linebreak = '\\n';\n",
    "    for i in range(m.shape[0]):\n",
    "        rowcontents = divider.join(str(x).rjust(cwidth) for x in m[i, :])\n",
    "        s += str(rnames[i]).rjust(rwidth) + divider + rowcontents + linebreak\n",
    "    print s\n",
    "    \n",
    "m = np.matrix([[1.0, 2.0], [3.0, 4.0]])\n",
    "m = row_norm(m); print m\n",
    "m = col_norm(m); print m\n",
    "\n",
    "#### Define encapsulating class\n",
    "\n",
    "class Module:\n",
    "    def __init__(self,\n",
    "                lexica=None,\n",
    "                baselexicon=None,\n",
    "                states=None,\n",
    "                costs=None,\n",
    "                messages=None,\n",
    "                prior=None,\n",
    "                lexprior=None,\n",
    "                lexcount=None, \n",
    "                temperature=1.0,\n",
    "                alpha=1.0,\n",
    "                beta=1.0,\n",
    "                nullmsg=True,\n",
    "                nullcost=5.0):\n",
    "        self.lexica = lexica\n",
    "        self.baselexicon = baselexicon\n",
    "        self.states = states\n",
    "        self.costs = costs\n",
    "        self.messages = messages\n",
    "        self.prior = prior\n",
    "        self.lexprior = lexprior\n",
    "        self.lexcount = lexcount\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta \n",
    "        self.nullmsg = nullmsg\n",
    "        self.nullcost = nullcost\n",
    "        \n",
    "        #intialise base prior arrays \n",
    "        if type(self.prior) == type(None):\n",
    "            val = 1.0/len(self.states)\n",
    "            self.prior = np.repeat(val, len(self.states))\n",
    "        if type(self.lexprior) == type(None) and self.lexcount != None:\n",
    "            val = 1.0/len(self.lexcount)\n",
    "            self.prior = np.repeat(val, len(self.lexcount))\n",
    "        else:\n",
    "            self.lexprior = defaultdict(lambda: 1.0)\n",
    "        if type(self.costs) == type(None):\n",
    "            self.costs = np.zeros(len(self.messages))\n",
    "            if self.nullmsg:\n",
    "                self.costs[-1] = self.nullcost\n",
    "        self.final_listener = np.zeros((len(self.messages), len(self.states)))\n",
    "        self.final_speaker = None  \n",
    "\n",
    "\n",
    "####  Interaction iterative functions\n",
    "\n",
    "    def rsa(self, lex=None):\n",
    "        if lex is None: lex = self.baselexicon\n",
    "        literal = self.l0(lex)\n",
    "        speaker = self.S(literal)\n",
    "        listener = self.L(speaker)\n",
    "        return [literal, speaker, listener]\n",
    "\n",
    "    def run_base_model(self, lex, n=2, display=True, digits=4):\n",
    "        return self.run(\n",
    "                    n=n, \n",
    "                    display=display, \n",
    "                    digits=digits,\n",
    "                    initial_listener = self.l0(lex),\n",
    "                    start_level=0)\n",
    "\n",
    "    def run(self,\n",
    "       initial_listener,\n",
    "       n=2,\n",
    "       display=True,\n",
    "       digits=4,\n",
    "       start_level=0,\n",
    "       ):\n",
    "    #langs\n",
    "        langs = [initial_listener]\n",
    "        for i in range(1, (n-1)*2, 2):\n",
    "            langs.append(self.S(langs[i-1]))\n",
    "            langs.append(self.L(langs[i]))\n",
    "        \n",
    "        if len(langs) < 2:\n",
    "            self.final_speaker = None\n",
    "            self.final_listener = langs[-1]\n",
    "        else:\n",
    "            self.final_speaker, self.final_listener = langs[-2:]\n",
    "        \n",
    "        if display:\n",
    "            self.display_iteration(langs, start_level=start_level, digits=digits)\n",
    "        return langs\n",
    "    \n",
    "\n",
    "#### Agents\n",
    "\n",
    "    def l0(self, lex):\n",
    "        return row_norm(lex*self.prior)\n",
    "\n",
    "    def L(self, speaker):\n",
    "        return self.l0(speaker.T)\n",
    "\n",
    "    def S(self, listener):\n",
    "        return row_norm(np.exp(self.temperature * ((self.alpha*safe_log(listener.T)) - self.costs)))\n",
    "\n",
    "    def s1(self, lex):\n",
    "        return self.S(self.l0(lex))\n",
    "\n",
    "    def l1(self, lex):\n",
    "        return self.L(self.s1(lex))\n",
    "\n",
    "    def lex_likelihood(self):\n",
    "        p = np.array([np.sum(self.s1(lex), axis=0) * self.lexprior[i] for i, lex in enumerate(self.lexica)])\n",
    "        return col_norm(p)\n",
    "\n",
    "    def listener_lexical_marginalisation(self, listener):\n",
    "        return np.sum(listener, axis=1)\n",
    "\n",
    "    def speaker_lexical_marginalisation(self, speaker):\n",
    "        return row_norm(np.sum(speaker, axis=0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSA Fundamentals:\n",
    "\n",
    "Elements: literal listener $L_0$, pragmatic speaker $S_1$, pragmatic listener $L_2$, cost function on dialogue (fixed utterances?) $\\kappa$, inverse temperature parameter $\\alpha$, prior probabilities of referents $P$, prior probabilities (truth functions?) of utterances referring to referents $L$, current referent $r$, current utterance $u$.\n",
    "\n",
    "Literal Listener:\n",
    "\n",
    "$l_o(r\\,|\\,u, L)\\,\\propto\\,L(u\\,|\\,r)\\,P(r)$\n",
    "\n",
    "\n",
    "\n",
    "Pragmatic Speaker:\n",
    "\n",
    "\n",
    "$s_1(u\\,|\\,r, L)\\,\\propto\\,e\\,^{\\alpha\\log{l_o(r\\,|\\,u, L)}\\,-\\,\\kappa(u)}$\n",
    "\n",
    "\n",
    "Pragmatic Listener:\n",
    "\n",
    "$l_2(r\\,|\\,u, L)\\,\\propto\\,s_1(u\\,|\\,t,\\,L)\\,P(r)$\n",
    "\n",
    "\n",
    "(Note: this back and forth nature addresses Grice's conversational implicature theory but poses an obvious paradoxical problem i.e., it is always optimal to soft-maximise the current previous agent i.e., use strategy $S_{n-1}$ at whatever iteration you are at and use Bayes ruleto invert their decision procedure. I think most of the work in this setting so far sets recursion depth = 3)\n",
    "\n",
    "Final equilibirium state currently is when only one agent is optimal wrt. the game, the other is $nearly$ optimal i.e., off by one iteration.\n",
    "\n",
    "### Elements\n",
    "\n",
    "Lexicon, states, costs, prior probabilities, temperature parameter, base speaker/listener, pragmatic (final?) speaker/listener, iterations, lexcount\n",
    "\n",
    "### Agents\n",
    "\n",
    "$l_0$: base listener that combines the prior probabilties with truth-conditional lexicon i.e., inner product of $lex$ and $self.prior$\n",
    "\n",
    "$l_1$: general listener that takes input from speaker and transposes matrix\n",
    "\n",
    "$s_1$: general speaker that takes input from listener and uses formula above i.e., weight/reason by the tempature parameter and incorporate costs\n",
    "\n",
    "$l_{uncertainty}$: for $n$ lexicons, this is a general listener that takes input from speaker, then performs operations for all lexicons i.e., reasons over the speaker's marginal and composes them together\n",
    "\n",
    "### Functions\n",
    "\n",
    "$rsa(lexicon)$: has a base listener, pragmatic speaker, pragmatic listener; iterates back and forth and returns the agents\n",
    "\n",
    "Define uncertainty etc., in detail\n",
    "\n",
    "### Utility Funtions\n",
    "\n",
    "transpose, row normalisation, column normalisation, inner product, powerset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
