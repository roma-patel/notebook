section 2: embedded implicatures. 

overview: a listener assumes that the speaker is co-operative in the Gricean sense of rational interaction. so the listener gets an utterance U with content p, and this meets the co-operative assumption if additional conditions are met (in some worlds). the listener can resolve this i.e., the conditions are met in many, but not all the cases, and the listener understands that the speaker intended for him to infer the truth of a different but related proposition q. this therefore still meets the criteria of a speaker choosing utterance U to ensure co-operative communication.

in all, speaker S can say utterance U for content p that may literally have led to listener inferring proposition q, but in some cases can lead to proposition q'?

scalar implicatures are tied to one of Grice's maxims; "be only as informative as required". e.g., saying "Player A hit some of the shots" likely implies that they did not hit all of the shots. (note that this is tied in with other observations and assumptions i.e., the full entirety of observances of the speaker)

implicature is accessible because it is an enrichment of one agent i.e., it strictly entails the original literal content. if a speaker says "some" the utterance's literal meaning and the implicature can be combined into a stronger meaning by intersection. 


lexical uncertainty: the semantic nature of a word is not always preserved and changes contextually. here, communicative context makes the most difference. another factor is that a person, based on the knowledge that he has, cannot be expected to think of words/concepts in the same way as another person (based on the knowledge and dataset and interactions he has been trained on). in the lexical uncertainty model, discourse participants are not presumed to share a single, fixed lexicon that maps words to meanings. there exist several lexica, and communicative behavior of agents also relies on their ability to synthesize information from the numerous lexica.

elements:

A grammar G that generates utterances (messages in set M) that are proposition-denoting; a domain D of entities; a set W of worlds; an interpretation function [[.]] and refinement function R(.).

M is a subset of expressions generated by G and these all denote some proposition. Also add the null message to M i.e., [[null]] = W (null message is true in all worlds).

L is a lexicon s.t., for all worlds, L(null, w) = 1 and for all messages, the set of all worlds s.t., L(m, w)=1 belongs to R(m).

P is a prior probability distribution over the set of worlds. 

C is a cost function on messages. for lexical items, costs are specified otherwise recursively added with depth of grammar.

P_l is a prior probability distribution over the set of lexica.


the base (literal) agents are fixed-lexicon agents, and the final listener reasons over all lexicons i.e., does not rely on a fixed lexicon. so the base listener l_0 defines a conditional distribution over worlds given the messages (how probable is a message in a world?). so given a message, the base listener estimates the relative likelihood of worlds that the message is true in. the speaker s_i observes a state w and chooses a message that allows the listener to best infer the intended meaning and then pick a referent.